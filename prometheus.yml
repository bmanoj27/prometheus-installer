# my global config
global:
  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
           - localhost:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  - "/etc/prometheus/rules/first_rule.yml"
  - "/etc/prometheus/rules/alert_test_rule.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: "prometheus"

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
      - targets: ["localhost:9090"]
       # The label name is added as a label `label_name=<label_value>` to any timeseries scraped from this config.
        labels:
          app: "prometheus"
#Custom Conifg Start

  - job_name: "node_exporter"
    basic_auth:
      username: "prometheus"
      password: "P@ssw0rd" 
    scheme: "https"
    tls_config:
      ca_file: /etc/prometheus/node_exporter.crt
      insecure_skip_verify: true
    static_configs:
      - targets: ["localhost:9100"]
        labels:
          app: "node_scrape"
#using a file to store the endpoints
  - job_name: "file-example"
    file_sd_configs:
      - files:
          - 'file-sa.json' # - '*.json' will also work, place the json in the same dir as this file, or provide full path
    relabel_configs:
      - source_labels: [team]
        regex: (.*)
        action: replace
        target_label: organization
        replacement: org-$1     #relabeling all team:* with organization:org-*. Example: team:alpha --> organization:org-alpha

#END
#AWS EC2 Instance Scrape
  - job_name: "aws_ec2"
    ec2_sd_configs:
      - region: us-east-1
        access_key: YOUR_AWS_ACCESS_KEY #KEY WITH JUST ONE PERMISSION: AmzonEC2ReadOnlyAccess
        secret_key: YOUR_AWS_SECRET_KEY #This config will scrape all ec2 instances
        port: 9100
    relabel_configs:
      - source_labels: [__meta_ec2_tag_Name]
        regex: webserver-.* #so, only instances with tag Name:webserver-* will be scraped
        action: keep
      - source_labels: [__meta_ec2_tag_env]
        regex: uat
        action: drop  #with uat will be dropped.
      - regex: instance|job
        action: labelkeep  #other than instance or job, all other labels will be dropped.
#Docker and cAdvisor Scrape
  - job_name: "docker"
    static_configs:
      - targets: ["localhost:9323"]
        labels:
          app: "docker"
  - job_name: cadvisor
    static_configs:
      - targets: ["localhost:8080"]
        labels:
          app: "cadvisor"